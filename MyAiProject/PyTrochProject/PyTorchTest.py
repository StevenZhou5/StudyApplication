import torch
import torchtext
import nltk

nltk.word_tokenize()

TEXT = torchtext.data.Field(tokenize='spacy')
torch.randn()
torchtext.data.BPTTIterator.splits()
torchtext.datasets.IMDB.splits()
open()

TEXT.build_vocab()