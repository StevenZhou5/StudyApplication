{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from _future_ import print_function\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Tensors的初始化\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建Tensors，Tensors(张量和numpy中的Array是类似的)\n",
    "x = torch.empty(5,3) \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2544, 0.7975, 0.2602],\n",
       "        [0.8312, 0.3923, 0.4843],\n",
       "        [0.2903, 0.6636, 0.9573],\n",
       "        [0.8015, 0.4656, 0.6307],\n",
       "        [0.7787, 0.1601, 0.5049]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构造一个随机初始化的矩阵：\n",
    "x = torch.rand(5,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构造一个矩阵全为 0，而且数据类型是 long.\n",
    "x = torch.zeros(5,3,dtype=torch.long)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构造一个张量，直接使用数据：\n",
    "x = torch.tensor([5.5,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 1.1930,  0.1685,  0.9254],\n",
      "        [-0.3051, -0.2144,  0.2007],\n",
      "        [-1.5648,  0.5953,  1.2923],\n",
      "        [ 0.4512, -0.0543,  0.7637],\n",
      "        [ 0.0019,  1.2586, -0.2726]])\n"
     ]
    }
   ],
   "source": [
    "#创建一个 tensor 基于已经存在的 tensor。\n",
    "x = x.new_ones(5,3,dtype=torch.double) # 把x重写为5*3矩阵，值全为1的矩阵\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x,dtype=torch.float32) # 重写数据类型和随机初始化\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#获取tensor的维度信息:\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#Tensors的操作\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9689, 0.8416, 1.0874],\n",
      "        [0.9712, 0.8663, 1.4279],\n",
      "        [1.1317, 0.7663, 0.4892],\n",
      "        [0.6902, 1.1174, 1.1547],\n",
      "        [0.9953, 0.8629, 1.5671]])\n",
      "tensor([[0.9689, 0.8416, 1.0874],\n",
      "        [0.9712, 0.8663, 1.4279],\n",
      "        [1.1317, 0.7663, 0.4892],\n",
      "        [0.6902, 1.1174, 1.1547],\n",
      "        [0.9953, 0.8629, 1.5671]])\n",
      "tensor([[0.9689, 0.8416, 1.0874],\n",
      "        [0.9712, 0.8663, 1.4279],\n",
      "        [1.1317, 0.7663, 0.4892],\n",
      "        [0.6902, 1.1174, 1.1547],\n",
      "        [0.9953, 0.8629, 1.5671]])\n",
      "tensor([[0.9689, 0.8416, 1.0874],\n",
      "        [0.9712, 0.8663, 1.4279],\n",
      "        [1.1317, 0.7663, 0.4892],\n",
      "        [0.6902, 1.1174, 1.1547],\n",
      "        [0.9953, 0.8629, 1.5671]])\n"
     ]
    }
   ],
   "source": [
    "#加法: 方式 1\n",
    "y = torch.rand(5,3)\n",
    "print(x+y)\n",
    "#加法: 方式2\n",
    "print(torch.add(x,y))\n",
    "#加法: 提供一个输出 tensor 作为参数\n",
    "result = torch.empty(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "print(result)\n",
    "#加法: in-place\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6580, 0.3648, 0.5429],\n",
      "        [0.9405, 0.0864, 0.8118],\n",
      "        [0.9224, 0.4878, 0.4246],\n",
      "        [0.4709, 0.6589, 0.6102],\n",
      "        [0.1849, 0.7958, 0.7116]])\n",
      "tensor([0.3648, 0.0864, 0.4878, 0.6589, 0.7958])\n"
     ]
    }
   ],
   "source": [
    "# 你可以使用标准的  NumPy 类似的索引操作\n",
    "print(x)\n",
    "print(x[:,1]) # 取出第二列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8]) torch.Size([8, 2])\n",
      "tensor([[ 0.2955, -0.9996,  1.1670,  0.7220],\n",
      "        [ 0.6128, -1.6132, -3.1525, -0.1491],\n",
      "        [-0.3752, -1.7521,  0.6885, -1.3096],\n",
      "        [-1.0361, -1.2292,  0.5437,  0.7229]]) \n",
      " tensor([ 0.2955, -0.9996,  1.1670,  0.7220,  0.6128, -1.6132, -3.1525, -0.1491,\n",
      "        -0.3752, -1.7521,  0.6885, -1.3096, -1.0361, -1.2292,  0.5437,  0.7229]) \n",
      " tensor([[ 0.2955, -0.9996,  1.1670,  0.7220,  0.6128, -1.6132, -3.1525, -0.1491],\n",
      "        [-0.3752, -1.7521,  0.6885, -1.3096, -1.0361, -1.2292,  0.5437,  0.7229]]) \n",
      " tensor([[ 0.2955, -0.9996],\n",
      "        [ 1.1670,  0.7220],\n",
      "        [ 0.6128, -1.6132],\n",
      "        [-3.1525, -0.1491],\n",
      "        [-0.3752, -1.7521],\n",
      "        [ 0.6885, -1.3096],\n",
      "        [-1.0361, -1.2292],\n",
      "        [ 0.5437,  0.7229]])\n"
     ]
    }
   ],
   "source": [
    "#改变大小：如果你想改变一个 tensor 的大小或者形状，你可以使用 torch.view:\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8) # size-1会根据其他维度的变化来进行推断出来：这个相当于把原来的两行合并成新的一行\n",
    "p = x.view(8,-1) # 这个相当于把原来的每行拆成两行\n",
    "print(x.size(),y.size(),z.size(),p.size())\n",
    "print(x,'\\n',y,'\\n',z,'\\n',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3954])\n",
      "-1.3954102993011475\n"
     ]
    }
   ],
   "source": [
    "#如果你的 tensor只有一个元素 ，使用 .item() 来获得这个 value 。\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_wrap__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__idiv__',\n",
       " '__ilshift__',\n",
       " '__imul__',\n",
       " '__index__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__long__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__reversed__',\n",
       " '__rfloordiv__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_backward_hooks',\n",
       " '_base',\n",
       " '_cdata',\n",
       " '_coalesced_',\n",
       " '_dimI',\n",
       " '_dimV',\n",
       " '_grad',\n",
       " '_grad_fn',\n",
       " '_indices',\n",
       " '_is_view',\n",
       " '_make_subclass',\n",
       " '_nnz',\n",
       " '_update_names',\n",
       " '_values',\n",
       " '_version',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'add',\n",
       " 'add_',\n",
       " 'addbmm',\n",
       " 'addbmm_',\n",
       " 'addcdiv',\n",
       " 'addcdiv_',\n",
       " 'addcmul',\n",
       " 'addcmul_',\n",
       " 'addmm',\n",
       " 'addmm_',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'addr_',\n",
       " 'align_as',\n",
       " 'align_to',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'any',\n",
       " 'apply_',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_strided',\n",
       " 'as_strided_',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan2_',\n",
       " 'atan_',\n",
       " 'backward',\n",
       " 'baddbmm',\n",
       " 'baddbmm_',\n",
       " 'bernoulli',\n",
       " 'bernoulli_',\n",
       " 'bfloat16',\n",
       " 'bincount',\n",
       " 'bitwise_not',\n",
       " 'bitwise_not_',\n",
       " 'bmm',\n",
       " 'bool',\n",
       " 'byte',\n",
       " 'cauchy_',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'char',\n",
       " 'cholesky',\n",
       " 'cholesky_inverse',\n",
       " 'cholesky_solve',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clamp_max',\n",
       " 'clamp_max_',\n",
       " 'clamp_min',\n",
       " 'clamp_min_',\n",
       " 'clone',\n",
       " 'coalesce',\n",
       " 'contiguous',\n",
       " 'copy_',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'cuda',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'data_ptr',\n",
       " 'dense_dim',\n",
       " 'dequantize',\n",
       " 'det',\n",
       " 'detach',\n",
       " 'detach_',\n",
       " 'device',\n",
       " 'diag',\n",
       " 'diag_embed',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'digamma',\n",
       " 'digamma_',\n",
       " 'dim',\n",
       " 'dist',\n",
       " 'div',\n",
       " 'div_',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'eig',\n",
       " 'element_size',\n",
       " 'eq',\n",
       " 'eq_',\n",
       " 'equal',\n",
       " 'erf',\n",
       " 'erf_',\n",
       " 'erfc',\n",
       " 'erfc_',\n",
       " 'erfinv',\n",
       " 'erfinv_',\n",
       " 'exp',\n",
       " 'exp_',\n",
       " 'expand',\n",
       " 'expand_as',\n",
       " 'expm1',\n",
       " 'expm1_',\n",
       " 'exponential_',\n",
       " 'fft',\n",
       " 'fill_',\n",
       " 'fill_diagonal_',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'float',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'fmod',\n",
       " 'fmod_',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'gather',\n",
       " 'ge',\n",
       " 'ge_',\n",
       " 'geometric_',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'get_device',\n",
       " 'grad',\n",
       " 'grad_fn',\n",
       " 'gt',\n",
       " 'gt_',\n",
       " 'half',\n",
       " 'hardshrink',\n",
       " 'has_names',\n",
       " 'histc',\n",
       " 'ifft',\n",
       " 'index_add',\n",
       " 'index_add_',\n",
       " 'index_copy',\n",
       " 'index_copy_',\n",
       " 'index_fill',\n",
       " 'index_fill_',\n",
       " 'index_put',\n",
       " 'index_put_',\n",
       " 'index_select',\n",
       " 'indices',\n",
       " 'int',\n",
       " 'int_repr',\n",
       " 'inverse',\n",
       " 'irfft',\n",
       " 'is_coalesced',\n",
       " 'is_complex',\n",
       " 'is_contiguous',\n",
       " 'is_cuda',\n",
       " 'is_distributed',\n",
       " 'is_floating_point',\n",
       " 'is_leaf',\n",
       " 'is_mkldnn',\n",
       " 'is_nonzero',\n",
       " 'is_pinned',\n",
       " 'is_quantized',\n",
       " 'is_same_size',\n",
       " 'is_set_to',\n",
       " 'is_shared',\n",
       " 'is_signed',\n",
       " 'is_sparse',\n",
       " 'isclose',\n",
       " 'item',\n",
       " 'kthvalue',\n",
       " 'layout',\n",
       " 'le',\n",
       " 'le_',\n",
       " 'lerp',\n",
       " 'lerp_',\n",
       " 'lgamma',\n",
       " 'lgamma_',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log10_',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log2',\n",
       " 'log2_',\n",
       " 'log_',\n",
       " 'log_normal_',\n",
       " 'log_softmax',\n",
       " 'logdet',\n",
       " 'logical_not',\n",
       " 'logical_not_',\n",
       " 'logical_xor',\n",
       " 'logical_xor_',\n",
       " 'logsumexp',\n",
       " 'long',\n",
       " 'lstsq',\n",
       " 'lt',\n",
       " 'lt_',\n",
       " 'lu',\n",
       " 'lu_solve',\n",
       " 'map2_',\n",
       " 'map_',\n",
       " 'masked_fill',\n",
       " 'masked_fill_',\n",
       " 'masked_scatter',\n",
       " 'masked_scatter_',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'matrix_power',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'mul_',\n",
       " 'multinomial',\n",
       " 'mv',\n",
       " 'mvlgamma',\n",
       " 'mvlgamma_',\n",
       " 'name',\n",
       " 'names',\n",
       " 'narrow',\n",
       " 'narrow_copy',\n",
       " 'ndim',\n",
       " 'ndimension',\n",
       " 'ne',\n",
       " 'ne_',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'nelement',\n",
       " 'new',\n",
       " 'new_empty',\n",
       " 'new_full',\n",
       " 'new_ones',\n",
       " 'new_tensor',\n",
       " 'new_zeros',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'normal_',\n",
       " 'numel',\n",
       " 'numpy',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'output_nr',\n",
       " 'permute',\n",
       " 'pin_memory',\n",
       " 'pinverse',\n",
       " 'polygamma',\n",
       " 'polygamma_',\n",
       " 'pow',\n",
       " 'pow_',\n",
       " 'prelu',\n",
       " 'prod',\n",
       " 'put_',\n",
       " 'q_per_channel_axis',\n",
       " 'q_per_channel_scales',\n",
       " 'q_per_channel_zero_points',\n",
       " 'q_scale',\n",
       " 'q_zero_point',\n",
       " 'qr',\n",
       " 'qscheme',\n",
       " 'random_',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'record_stream',\n",
       " 'refine_names',\n",
       " 'register_hook',\n",
       " 'reinforce',\n",
       " 'relu',\n",
       " 'relu_',\n",
       " 'remainder',\n",
       " 'remainder_',\n",
       " 'rename',\n",
       " 'rename_',\n",
       " 'renorm',\n",
       " 'renorm_',\n",
       " 'repeat',\n",
       " 'repeat_interleave',\n",
       " 'requires_grad',\n",
       " 'requires_grad_',\n",
       " 'reshape',\n",
       " 'reshape_as',\n",
       " 'resize',\n",
       " 'resize_',\n",
       " 'resize_as',\n",
       " 'resize_as_',\n",
       " 'retain_grad',\n",
       " 'rfft',\n",
       " 'roll',\n",
       " 'rot90',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'scatter',\n",
       " 'scatter_',\n",
       " 'scatter_add',\n",
       " 'scatter_add_',\n",
       " 'select',\n",
       " 'set_',\n",
       " 'shape',\n",
       " 'share_memory_',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'sign_',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'size',\n",
       " 'slogdet',\n",
       " 'smm',\n",
       " 'softmax',\n",
       " 'solve',\n",
       " 'sort',\n",
       " 'sparse_dim',\n",
       " 'sparse_mask',\n",
       " 'sparse_resize_',\n",
       " 'sparse_resize_and_clear_',\n",
       " 'split',\n",
       " 'split_with_sizes',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'squeeze',\n",
       " 'squeeze_',\n",
       " 'sspaddmm',\n",
       " 'std',\n",
       " 'stft',\n",
       " 'storage',\n",
       " 'storage_offset',\n",
       " 'storage_type',\n",
       " 'stride',\n",
       " 'sub',\n",
       " 'sub_',\n",
       " 'sum',\n",
       " 'sum_to_size',\n",
       " 'svd',\n",
       " 'symeig',\n",
       " 't',\n",
       " 't_',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " 'to',\n",
       " 'to_dense',\n",
       " 'to_mkldnn',\n",
       " 'to_sparse',\n",
       " 'tolist',\n",
       " 'topk',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'transpose_',\n",
       " 'triangular_solve',\n",
       " 'tril',\n",
       " 'tril_',\n",
       " 'triu',\n",
       " 'triu_',\n",
       " 'trunc',\n",
       " 'trunc_',\n",
       " 'type',\n",
       " 'type_as',\n",
       " 'unbind',\n",
       " 'unflatten',\n",
       " 'unfold',\n",
       " 'uniform_',\n",
       " 'unique',\n",
       " 'unique_consecutive',\n",
       " 'unsqueeze',\n",
       " 'unsqueeze_',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'view_as',\n",
       " 'where',\n",
       " 'zero_']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(x)\n",
    "x.transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.5485, -1.4282, -2.0670]],\n",
      "\n",
      "        [[-0.0609,  0.9265, -1.4946]]])\n",
      "tensor([[[ 1.5485, -0.0609]],\n",
      "\n",
      "        [[-1.4282,  0.9265]],\n",
      "\n",
      "        [[-2.0670, -1.4946]]])\n",
      "tensor([[[ 1.5485, -0.0609]],\n",
      "\n",
      "        [[-1.4282,  0.9265]],\n",
      "\n",
      "        [[-2.0670, -1.4946]]])\n",
      "tensor([[[ 1.5485, -1.4282, -2.0670],\n",
      "         [-0.0609,  0.9265, -1.4946]]])\n",
      "tensor([[[ 1.5485],\n",
      "         [-1.4282],\n",
      "         [-2.0670]],\n",
      "\n",
      "        [[-0.0609],\n",
      "         [ 0.9265],\n",
      "         [-1.4946]]])\n"
     ]
    }
   ],
   "source": [
    "# 转置操作\n",
    "x = torch.randn(2,1,3)\n",
    "print(x)\n",
    "print(x.T) # 默认是第一维和最后一维进行转置\n",
    "# print(torch.t(x)) # 普通的转置操作,只能进行2维矩阵的转置\n",
    "\n",
    "print(torch.transpose(x,0,2)) # 由两行(0维)3列(2维)变为了三行(0维)两列(2维度)\n",
    "print(torch.transpose(x,0,1)) # 由两行(0维)一列(1维)变为了一行(0维)两列(1维度)\n",
    "print(torch.transpose(x,1,2)) # 有一行（1维）3列(2维)变成了3行(1维)1列（2维）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Numpy 与 Tensor 之间相互转换\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "# Numpy 与 Tensor 之间相互转换\n",
    "# 注意Torch的Tensor和numpy的Array会共享他们的存储空间，修改一个会导致另外的一个也被修改\n",
    "# 将tensor转化为Numpy Array：\n",
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)\n",
    "\n",
    "# 当修改了tensor之后，与之相关联的numpy array的值也被修改了\n",
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)\n",
    "\n",
    "# 将array转换为tensor\n",
    "c = torch.Tensor(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果有CUDA，可运行此段代码\n",
    "# 将使用“torch.device”对象来移动我们的tensors从GPU到我们想去的设备\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") # 一个CUDA设备对象\n",
    "    y = torch.ones_like(x,device=device) # 直接在GPU上创建一个tensor\n",
    "    x = x.to(device) # 或者直接使用字符串“.to(\"cuda\")”\n",
    "    z = x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double)) # \".to\"函数同时可以修改数据类型\n",
    "# 如果安装了CUDA后打印出来的结果\n",
    "# out\n",
    "# tensor([0.1252],device=’cuda:0‘)\n",
    "# tensor([0.1252],dtype=torch.float64)\n",
    "\n",
    "# 如果是GPU的数据要转成numpy array要先转成cpu数据在转:因为numpy只在cpu上运行\n",
    "# y.to(\"cpu\").data.numpy()\n",
    "# 或者 y.cpu().data.numpy()\n",
    "\n",
    "# model = model.cuda() # 把模型变为cuda()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
